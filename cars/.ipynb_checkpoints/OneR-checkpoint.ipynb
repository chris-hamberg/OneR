{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneR Classification\n",
    "- predict whether a car is desirable to purchase with 71.1% accuracy\n",
    "\n",
    "data source: <a href='car.data'>archive.ics.uci.edu/ml/datasets/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title: Car Evaluation Database\n",
      "\n",
      "2. Sources:\n",
      "   (a) Creator: Marko Bohanec\n",
      "   (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si)\n",
      "               Blaz Zupan      (blaz.zupan@ijs.si)\n",
      "   (c) Date: June, 1997\n",
      "\n",
      "3. Past Usage:\n",
      "\n",
      "   The hierarchical decision model, from which this dataset is\n",
      "   derived, was first presented in \n",
      "\n",
      "   M. Bohanec and V. Rajkovic: Knowledge acquisition and explanation for\n",
      "   multi-attribute decision making. In 8th Intl Workshop on Expert\n",
      "   Systems and their Applications, Avignon, France. pages 59-78, 1988.\n",
      "\n",
      "   Within machine-learning, this dataset was used for the evaluation\n",
      "   of HINT (Hierarchy INduction Tool), which was proved to be able to\n",
      "   completely reconstruct the original hierarchical model. This,\n",
      "   together with a comparison with C4.5, is presented in\n",
      "\n",
      "   B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by\n",
      "   function decomposition. ICML-97, Nashville, TN. 1997 (to appear)\n",
      "\n",
      "4. Relevant Information Paragraph:\n",
      "\n",
      "   Car Evaluation Database was derived from a simple hierarchical\n",
      "   decision model originally developed for the demonstration of DEX\n",
      "   (M. Bohanec, V. Rajkovic: Expert system for decision\n",
      "   making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates\n",
      "   cars according to the following concept structure:\n",
      "\n",
      "   CAR                      car acceptability\n",
      "   . PRICE                  overall price\n",
      "   . . buying               buying price\n",
      "   . . maint                price of the maintenance\n",
      "   . TECH                   technical characteristics\n",
      "   . . COMFORT              comfort\n",
      "   . . . doors              number of doors\n",
      "   . . . persons            capacity in terms of persons to carry\n",
      "   . . . lug_boot           the size of luggage boot\n",
      "   . . safety               estimated safety of the car\n",
      "\n",
      "   Input attributes are printed in lowercase. Besides the target\n",
      "   concept (CAR), the model includes three intermediate concepts:\n",
      "   PRICE, TECH, COMFORT. Every concept is in the original model\n",
      "   related to its lower level descendants by a set of examples (for\n",
      "   these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\n",
      "\n",
      "   The Car Evaluation Database contains examples with the structural\n",
      "   information removed, i.e., directly relates CAR to the six input\n",
      "   attributes: buying, maint, doors, persons, lug_boot, safety.\n",
      "\n",
      "   Because of known underlying concept structure, this database may be\n",
      "   particularly useful for testing constructive induction and\n",
      "   structure discovery methods.\n",
      "\n",
      "5. Number of Instances: 1728\n",
      "   (instances completely cover the attribute space)\n",
      "\n",
      "6. Number of Attributes: 6\n",
      "\n",
      "7. Attribute Values:\n",
      "\n",
      "   buying       v-high, high, med, low\n",
      "   maint        v-high, high, med, low\n",
      "   doors        2, 3, 4, 5-more\n",
      "   persons      2, 4, more\n",
      "   lug_boot     small, med, big\n",
      "   safety       low, med, high\n",
      "\n",
      "8. Missing Attribute Values: none\n",
      "\n",
      "9. Class Distribution (number of instances per class)\n",
      "\n",
      "   class      N          N[%]\n",
      "   -----------------------------\n",
      "   unacc     1210     (70.023 %) \n",
      "   acc        384     (22.222 %) \n",
      "   good        69     ( 3.993 %) \n",
      "   v-good      65     ( 3.762 %) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('car.names') as fhand:\n",
    "    doc = fhand.read()\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame View\n",
    "- first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class'] \n",
    "dfile = 'car.data'\n",
    "df = pd.read_csv(dfile, header=None, names=names)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying          0\n",
       "maint           0\n",
       "doors           2\n",
       "persons         2\n",
       "lug_boot        0\n",
       "safety          1\n",
       "class       unacc\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy = dict.fromkeys(set(df[\"buying\"]))\n",
    "buy[\"vhigh\"] = 0; buy[\"high\"] = 1\n",
    "buy[\"med\"] = 2; buy[\"low\"] = 3 \n",
    "df[\"buying\"] = df[\"buying\"].apply(lambda k: buy[k]) \n",
    "\n",
    "maint = buy\n",
    "df[\"maint\"] = df[\"maint\"].apply(lambda k: buy[k]) \n",
    "\n",
    "predicate = lambda n: int(n) if n.isnumeric() else 5\n",
    "\n",
    "df[\"doors\"] = df[\"doors\"].apply(predicate) \n",
    "\n",
    "df[\"persons\"] = df[\"persons\"].apply(predicate)\n",
    "\n",
    "boot = dict.fromkeys(set(df[\"lug_boot\"]))\n",
    "boot[\"small\"] = 0; boot[\"med\"] = 1; boot[\"big\"] = 2\n",
    "df[\"lug_boot\"] = df[\"lug_boot\"].apply(lambda k: boot[k])\n",
    "\n",
    "safe = dict.fromkeys(set(df[\"safety\"]))\n",
    "safe[\"low\"] = 0; safe[\"med\"] = 1; safe[\"high\"] = 2\n",
    "df[\"safety\"] = df[\"safety\"].apply(lambda k: safe[k]) \n",
    "\n",
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"class\"], axis=1).values\n",
    "y = df[\"class\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneR Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_feature_value(X, y_true, feature_index, value):\n",
    "    class_counts = defaultdict(int)\n",
    "    for sample, y in zip(X, y_true):\n",
    "        if sample[feature_index] == value:\n",
    "            class_counts[y] += 1\n",
    "    sorted_class_counts = sorted(class_counts.items(),\n",
    "                                key=itemgetter(1), reverse=True)\n",
    "    most_frequent_class = sorted_class_counts[0][0]\n",
    "    incorrect_predictions = [class_count for class_value, class_count\n",
    "                            in class_counts.items()\n",
    "                            if class_value != most_frequent_class]\n",
    "    error = sum(incorrect_predictions)\n",
    "    return most_frequent_class, error\n",
    "\n",
    "def train_on_feature(X, y_true, feature_index):\n",
    "    values = set(X[:,feature_index])\n",
    "    predictors = {}\n",
    "    errors = []\n",
    "    for current_value in values:\n",
    "        most_frequent_class, error = train_feature_value(\n",
    "            X, y_true, feature_index, current_value\n",
    "        )\n",
    "        predictors[current_value] = most_frequent_class\n",
    "        errors.append(error)\n",
    "    total_error = sum(errors)\n",
    "    return predictors, total_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is base on feature 0 and has 393.00 errors\n"
     ]
    }
   ],
   "source": [
    "all_predictors = {}\n",
    "errors = {}\n",
    "\n",
    "for feature_index in range(X_train.shape[1]):\n",
    "    predictors, total_error = train_on_feature(X_train, y_train, feature_index)\n",
    "    all_predictors[feature_index] = predictors\n",
    "    errors[feature_index] = total_error\n",
    "    \n",
    "best_feature, best_error = sorted(errors.items(), key=itemgetter(1))[0]\n",
    "\n",
    "print('The best model is base on feature {0} and has {1:.2f} errors'.format(\n",
    "        best_feature, best_error)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature': 0, 'predictor': {0: 'unacc', 1: 'unacc', 2: 'unacc', 3: 'unacc'}}\n"
     ]
    }
   ],
   "source": [
    "model = {'feature': best_feature, 'predictor': all_predictors[best_feature]}\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model):\n",
    "    var = model['feature']\n",
    "    predictor = model['predictor']\n",
    "    predicted = np.array([\n",
    "        predictor[int(sample[var])] for sample in X_test\n",
    "    ])\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict(X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is 71.1%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predicted == y_test) * 100\n",
    "print('The test accuracy is {:.1f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.00      0.00      0.00        84\n",
      "        good       0.00      0.00      0.00        19\n",
      "       unacc       0.71      1.00      0.83       307\n",
      "       vgood       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       432\n",
      "   macro avg       0.18      0.25      0.21       432\n",
      "weighted avg       0.51      0.71      0.59       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
